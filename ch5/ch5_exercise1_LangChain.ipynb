{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8957fc14",
   "metadata": {
    "id": "8957fc14"
   },
   "source": [
    "# Exercise Task: Create a Recipe Generation App Using LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56827f8e",
   "metadata": {
    "id": "56827f8e"
   },
   "source": [
    "Your objective is to develop an application using LangChain. This application should be designed to receive user input in the form of a grocery list and generate a corresponding recipe as its output.\n",
    "\n",
    "You can use one up to N number of grceries as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0c6ac0",
   "metadata": {
    "id": "2d0c6ac0"
   },
   "source": [
    "Install requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05be01ed",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32040,
     "status": "ok",
     "timestamp": 1700881151869,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "05be01ed",
    "outputId": "ed8a3a05-07a2-4d02-e24f-f68b2ca8287b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.8/220.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "%pip install langchain --quiet\n",
    "%pip install openai --quiet\n",
    "%pip install python-dotenv --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21e1335",
   "metadata": {
    "id": "e21e1335"
   },
   "source": [
    "Add OpenAI api key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90b42145",
   "metadata": {
    "executionInfo": {
     "elapsed": 711,
     "status": "ok",
     "timestamp": 1700881152575,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "90b42145",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2670a4d",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1700881152576,
     "user": {
      "displayName": "Gunnar Kleemann",
      "userId": "02122813220075330457"
     },
     "user_tz": 360
    },
    "id": "d2670a4d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#from dotenv import load_dotenv\n",
    "import langchain\n",
    "\n",
    "openai.api_key = openai_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e92331c",
   "metadata": {
    "id": "7e92331c"
   },
   "source": [
    "Define LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecfcd8d",
   "metadata": {
    "id": "aecfcd8d"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ed1b87",
   "metadata": {
    "id": "d2ed1b87"
   },
   "source": [
    "Fill in list of groceries into a string:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b654a9b",
   "metadata": {
    "id": "2b654a9b"
   },
   "outputs": [],
   "source": [
    "list_of_groceries = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce967d1",
   "metadata": {
    "id": "8ce967d1"
   },
   "source": [
    "Create Template string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791591b0",
   "metadata": {
    "id": "791591b0"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d508d8bd",
   "metadata": {
    "id": "d508d8bd"
   },
   "source": [
    "Create PromptTemplate object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90d5296",
   "metadata": {
    "id": "f90d5296"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bd6ca0",
   "metadata": {
    "id": "19bd6ca0"
   },
   "source": [
    "Format Template (to create final prompt text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d6048",
   "metadata": {
    "id": "f65d6048"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655d74e2",
   "metadata": {
    "id": "655d74e2"
   },
   "source": [
    "Generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2163774c",
   "metadata": {
    "id": "2163774c"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68869bfa-c1a4-4cb5-91ea-ae22f16166d0",
   "metadata": {
    "id": "e80a3ca8"
   },
   "source": [
    "Create a toy dataset and template that is specific to a sales pipeline. lets say that you want to recommend that a user buy a computer with certain specifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47de772f-ca1e-4e79-bdf0-399ffae157c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca94c3b6-b02d-4229-a6ac-0c2c8355beb5",
   "metadata": {},
   "source": [
    "create a mini catalog cycle through the items and see if you can get item specific responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da04c4b-5fec-42bc-97f3-0c563e04d03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
